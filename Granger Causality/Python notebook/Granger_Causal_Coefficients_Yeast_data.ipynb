{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Granger Casuality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression on time series analysis.\n",
    "#Based on the discussion with professor Dantong Yu ,\n",
    "#I need to implement the ridge, lasso, elastic regression on the time series data.\n",
    "#The data is taken from the dtyu-granger-causality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat  # this is the SciPy module that loads mat-files\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, time\n",
    "import pandas as pd\n",
    "from numpy.linalg import inv\n",
    "mat = loadmat(r'C:\\Users\\dantongyu\\Downloads\\dtyu-granger-causality\\dtyu-granger-causality-645084c3e1f5\\SimulationExperiment\\Ridge\\analysis\\lambda_1_case_study\\filter_norm_expression.mat')  # load mat-file\n",
    "mdata = mat['expression']\n",
    "mdata=np.asmatrix(mdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mdata[:,3])\n",
    "mdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.20917326,  0.30489817,  0.26259475, -0.10205479, -0.55465239],\n",
       "        [ 0.10597167,  0.49453251, -0.06722951, -0.45352422, -0.71827714],\n",
       "        [ 0.23981549, -0.11018578,  0.50018292,  1.05755325,  1.26369524],\n",
       "        ...,\n",
       "        [ 0.78295462,  0.69103037,  0.3373717 , -0.0368846 , -0.38448166],\n",
       "        [ 0.07799073,  0.1208465 , -0.06927812, -0.41973049, -0.69267765],\n",
       "        [-0.03472913, -1.04344869, -0.43308817, -0.46962836, -1.3733422 ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.20917326,  0.30489817],\n",
       "        [ 0.10597167,  0.49453251],\n",
       "        [ 0.23981549, -0.11018578],\n",
       "        ...,\n",
       "        [ 0.78295462,  0.69103037],\n",
       "        [ 0.07799073,  0.1208465 ],\n",
       "        [-0.03472913, -1.04344869]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.10205479, -0.55465239, -0.91629071, ..., -0.51543144,\n",
       "         -0.84607069, -1.13384379],\n",
       "        [-0.45352422, -0.71827714, -0.64472399, ..., -0.80413433,\n",
       "         -0.83236472, -0.83008514],\n",
       "        [ 1.05755325,  1.26369524,  1.551796  , ..., -0.13748383,\n",
       "         -0.42509869, -0.67548787],\n",
       "        ...,\n",
       "        [-0.0368846 , -0.38448166, -0.20084109, ...,  0.48779431,\n",
       "          0.77215343,  1.23137852],\n",
       "        [-0.41973049, -0.69267765, -0.89082296, ..., -0.91779605,\n",
       "         -0.67734844, -0.40470891],\n",
       "        [-0.46962836, -1.3733422 , -1.6085277 , ...,  0.5288358 ,\n",
       "          0.05318378, -0.33220694]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.55465239, -0.91629071, -1.12559868, ..., -0.51543144,\n",
       "         -0.84607069, -1.13384379],\n",
       "        [-0.71827714, -0.64472399, -1.00620094, ..., -0.80413433,\n",
       "         -0.83236472, -0.83008514],\n",
       "        [ 1.26369524,  1.551796  ,  1.48968684, ..., -0.13748383,\n",
       "         -0.42509869, -0.67548787],\n",
       "        ...,\n",
       "        [-0.38448166, -0.20084109,  0.106374  , ...,  0.48779431,\n",
       "          0.77215343,  1.23137852],\n",
       "        [-0.69267765, -0.89082296, -0.71477305, ..., -0.91779605,\n",
       "         -0.67734844, -0.40470891],\n",
       "        [-1.3733422 , -1.6085277 , -0.87771077, ...,  0.5288358 ,\n",
       "          0.05318378, -0.33220694]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdata[:,4:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Granger Casuality model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat  # this is the SciPy module that loads mat-files\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, time\n",
    "import pandas as pd\n",
    "from numpy.linalg import inv\n",
    "mat = loadmat(r'C:\\Users\\dantongyu\\Downloads\\dtyu-granger-causality\\dtyu-granger-causality-645084c3e1f5\\SimulationExperiment\\Ridge\\analysis\\lambda_1_case_study\\filter_norm_expression.mat')  # load mat-file\n",
    "mdata = mat['expression']\n",
    "mdata=np.asmatrix(mdata)\n",
    "# Here they are taking the period as 3.\n",
    "# Here n_gene is nothing but the number of sensors in IOT data set.\n",
    "period=3\n",
    "temp=mdata.shape\n",
    "n_gene=temp[0]\n",
    "Time_samples=temp[1]\n",
    "m=Time_samples-period\n",
    "#Y is starting its values for 2000 genes from the p+1 time instant till Time\n",
    "Y=mdata[:,period:Time_samples].T\n",
    "# Transpose is performed by .T as mdata is a matrix and the dimensions of the Y ----> m x n as shown in the paper\n",
    "# Here you take for all the variables at time t\n",
    "X=np.matlib.zeros((m, n_gene*period))\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(period):\n",
    "        #I have to take the large slices to run it faster\n",
    "#         print(X[i,n_gene*(j):n_gene*(j+1)].shape, (mdata[:,i+period-j-1].T).shape )\n",
    "        X[i,n_gene*(j):n_gene*(j+1)]=mdata[:,i+period-j-1].T\n",
    "#T-2 in python is nothing but T-1 matlab notation in reality   \n",
    "def ridge_regression(X,Y,lambd):\n",
    "    i=X.shape[1]\n",
    "    B= inv(X.T*X + lambd*np.identity(i))*X.T*Y\n",
    "    return B\n",
    "B=ridge_regression(X,Y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.88875370e-03,  1.03049437e-03, -5.81152632e-04, ...,\n",
       "         -1.42728660e-03, -1.57448314e-04, -7.05962898e-04],\n",
       "        [ 2.26024620e-03,  1.93338602e-03, -1.58128823e-03, ...,\n",
       "         -1.80059223e-03,  9.09563223e-04, -6.25442300e-04],\n",
       "        [-2.54249065e-03, -2.91138199e-03,  4.01028619e-03, ...,\n",
       "          7.97026608e-04, -2.30103356e-03, -1.17944503e-03],\n",
       "        ...,\n",
       "        [ 2.21168228e-04,  3.07428608e-04,  4.77321830e-04, ...,\n",
       "         -1.19142851e-03,  3.66869192e-04, -2.30693134e-03],\n",
       "        [ 1.13371643e-03,  6.10932112e-04, -3.07595046e-05, ...,\n",
       "         -1.33472738e-03, -3.16211554e-04, -8.15122703e-04],\n",
       "        [ 2.31246624e-03,  2.61543414e-03, -2.57835436e-03, ...,\n",
       "         -1.81850406e-03,  1.66663016e-03, -1.11274082e-03]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values correspond to the output values of matlab code 0.00188875370339981 0.00103049436791531 -0.000581152631889214"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression using time series sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape,Y.shape (17, 3000) (17, 1000)\n",
      "B in paper corresponds to  [[ 1.65779731e-03  9.17510157e-04 -6.54011508e-04 ... -1.51265843e-03\n",
      "  -1.06766501e-04 -6.77336340e-04]\n",
      " [ 2.09043660e-03  1.85053929e-03 -1.63531888e-03 ... -1.86372496e-03\n",
      "   9.47124377e-04 -6.04465176e-04]\n",
      " [-2.41993251e-03 -2.85197174e-03  4.05030698e-03 ...  8.42494388e-04\n",
      "  -2.32873080e-03 -1.19518266e-03]\n",
      " ...\n",
      " [ 3.40159197e-04  3.65356119e-04  5.15357763e-04 ... -1.14803175e-03\n",
      "   3.40447299e-04 -2.32273477e-03]\n",
      " [ 1.15207667e-03  6.19880909e-04 -2.49897997e-05 ... -1.32808154e-03\n",
      "  -3.20372241e-04 -8.17602890e-04]\n",
      " [ 2.35404484e-03  2.63618515e-03 -2.56615857e-03 ... -1.80383624e-03\n",
      "   1.65801562e-03 -1.11815008e-03]] and its shape (3000, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, Y)\n",
    "#Y_pred_lin = linreg.predict(X_test)\n",
    "#print(\"Linear regression score\", linreg.score(X, Y))\n",
    "print(\"X.shape,Y.shape\",X.shape,Y.shape)\n",
    "# print(\"B Matrix and its shape\",linreg.coef_,linreg.coef_.shape)\n",
    "print(\"B in paper corresponds to \",np.transpose(linreg.coef_),\"and its shape\", np.transpose(linreg.coef_).shape)\n",
    "#print(\"Root mean Square Error on the test data\", np.sqrt(mean_squared_error(Y_test, Y_pred_lin)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It optimizes the following objective function\n",
    "\n",
    "||y - Xw||^2_2 + alpha * ||w||^2_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B in paper corresponds to  [[ 1.65754769e-03  9.17491569e-04 -6.53940650e-04 ... -1.51246795e-03\n",
      "  -1.06667510e-04 -6.77249282e-04]\n",
      " [ 2.09002221e-03  1.85018841e-03 -1.63487796e-03 ... -1.86330646e-03\n",
      "   9.46950273e-04 -6.04302081e-04]\n",
      " [-2.41936474e-03 -2.85120374e-03  4.04904855e-03 ...  8.42388881e-04\n",
      "  -2.32807625e-03 -1.19473611e-03]\n",
      " ...\n",
      " [ 3.40108221e-04  3.65560973e-04  5.14766386e-04 ... -1.14760842e-03\n",
      "   3.40745873e-04 -2.32170257e-03]\n",
      " [ 1.15204136e-03  6.19888488e-04 -2.49904716e-05 ... -1.32797607e-03\n",
      "  -3.20236339e-04 -8.17398487e-04]\n",
      " [ 2.35345346e-03  2.63546680e-03 -2.56545081e-03 ... -1.80340347e-03\n",
      "   1.65762795e-03 -1.11783104e-03]] and its shape (3000, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "clf = Ridge(alpha=1)\n",
    "clf.fit(X, Y)\n",
    "#print(clf.coef_)\n",
    "print(\"B in paper corresponds to \",np.transpose(clf.coef_),\"and its shape\", np.transpose(clf.coef_).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It optimizes the following objective function\n",
    "\n",
    "(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B in paper corresponds to  [[ 0.  0. -0. ... -0. -0. -0.]\n",
      " [ 0.  0. -0. ... -0.  0. -0.]\n",
      " [-0. -0.  0. ...  0. -0. -0.]\n",
      " ...\n",
      " [ 0.  0. -0. ... -0.  0. -0.]\n",
      " [ 0.  0. -0. ... -0.  0. -0.]\n",
      " [ 0.  0. -0. ... -0.  0. -0.]] and its shape (3000, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "clf = Lasso(alpha=1)\n",
    "clf.fit(X, Y)\n",
    "#print(clf.coef_)\n",
    "print(\"B in paper corresponds to \",np.transpose(clf.coef_),\"and its shape\", np.transpose(clf.coef_).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It optimizes the following objective function\n",
    "\n",
    "1 / (2 * n_samples) * ||y - Xw||^2_2 + alpha * l1_ratio * ||w||_1  + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
    "\n",
    "\n",
    "If you are interested in controlling the L1 and L2 penalty separately, keep in mind that this is equivalent to:\n",
    "\n",
    "a * L1 + b * L2\n",
    "\n",
    "where:\n",
    "\n",
    "alpha = a + b and l1_ratio = a / (a + b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B in paper corresponds to  [[ 0.  0. -0. ... -0. -0. -0.]\n",
      " [ 0.  0. -0. ... -0.  0. -0.]\n",
      " [-0. -0.  0. ...  0. -0. -0.]\n",
      " ...\n",
      " [ 0.  0. -0. ... -0.  0. -0.]\n",
      " [ 0.  0. -0. ... -0.  0. -0.]\n",
      " [ 0.  0. -0. ... -0.  0. -0.]] and its shape (3000, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "clf = Lasso(random_state=0)\n",
    "clf.fit(X, Y)\n",
    "#print(clf.coef_)\n",
    "# If you run the command stand alone, you will get the following clf.fit(X, y) You can change those parameters if the performance is too bad.\n",
    "# ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
    "#       max_iter=1000, normalize=False, positive=False, precompute=False,\n",
    "#       random_state=0, selection='cyclic', tol=0.0001, warm_start=False)\n",
    "print(\"B in paper corresponds to \",np.transpose(clf.coef_),\"and its shape\", np.transpose(clf.coef_).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
