{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Granger Casuality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression on time series analysis.\n",
    "# Based on the discussion with professor Dantong Yu ,\n",
    "# I need to implement the ridge, lasso, elastic regression on the time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat  # this is the SciPy module that loads mat-files\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, time\n",
    "import pandas as pd\n",
    "from numpy.linalg import inv\n",
    "# mat = loadmat(r'C:\\Users\\dantongyu\\Downloads\\dtyu-granger-causality\\dtyu-granger-causality-645084c3e1f5\\SimulationExperiment\\Ridge\\analysis\\lambda_1_case_study\\filter_norm_expression.mat')  # load mat-file\n",
    "# mdata = mat['expression']\n",
    "# mdata=np.asmatrix(mdata)\n",
    "df=pd.read_csv(r\"C:\\Users\\dantongyu\\Desktop\\Internship\\Granger Causality\\Python notebook\\data_vertical.csv\")\n",
    "#Its always better to perform normalization with respect to the particular sensor value\n",
    "#df = (df - df.min())/(df.max()-df.min())\n",
    "list_all=[df['Sensor1'].values,df['Sensor2'].values,df['Sensor3'].values,df['Sensor4'].values,df['Sensor5'].values]\n",
    "mdata=np.asmatrix(list_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Granger Casuality model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat  # this is the SciPy module that loads mat-files\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, time\n",
    "import pandas as pd\n",
    "from numpy.linalg import inv\n",
    "# mat = loadmat(r'C:\\Users\\dantongyu\\Downloads\\dtyu-granger-causality\\dtyu-granger-causality-645084c3e1f5\\SimulationExperiment\\Ridge\\analysis\\lambda_1_case_study\\filter_norm_expression.mat')  # load mat-file\n",
    "# mdata = mat['expression']\n",
    "# mdata=np.asmatrix(mdata)\n",
    "# Here they are taking the period as 3.\n",
    "# Here n_gene is nothing but the number of sensors in IOT data set.\n",
    "period=3\n",
    "temp=mdata.shape\n",
    "n_gene=temp[0]\n",
    "Time_samples=temp[1]\n",
    "m=Time_samples-period\n",
    "#Y is starting its values for 2000 genes from the p+1 time instant till Time\n",
    "Y=mdata[:,period:Time_samples].T\n",
    "# Transpose is performed by .T as mdata is a matrix and the dimensions of the Y ----> m x n as shown in the paper\n",
    "# Here you take for all the variables at time t\n",
    "X=np.matlib.zeros((m, n_gene*period))\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(period):\n",
    "        #I have to take the large slices to run it faster\n",
    "#         print(X[i,n_gene*(j):n_gene*(j+1)].shape, (mdata[:,i+period-j-1].T).shape )\n",
    "        X[i,n_gene*(j):n_gene*(j+1)]=mdata[:,i+period-j-1].T\n",
    "#T-2 in python is nothing but T-1 matlab notation in reality   \n",
    "def ridge_regression(X,Y,lambd):\n",
    "    i=X.shape[1]\n",
    "    B= inv(X.T*X + lambd*np.identity(i))*X.T*Y\n",
    "    return B\n",
    "B=ridge_regression(X,Y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 5)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values correspond to the output values of matlab code 0.00188875370339981 0.00103049436791531 -0.000581152631889214"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression using time series sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape,Y.shape (1776, 15) (1776, 5)\n",
      "B in paper corresponds to  [[ 0.54246708  0.22644204  0.19100316  0.05005768  0.04794428]\n",
      " [ 0.30868164  0.59260431  0.29449734 -0.18606384 -0.13654828]\n",
      " [ 0.33381149  0.34553924  0.67250749  0.02657549 -0.05014089]\n",
      " [ 0.13745035  0.15789439  0.16081838  0.99333057  0.66824195]\n",
      " [-0.08254336 -0.09409013 -0.08901601  0.34078243  0.66111746]\n",
      " [ 0.16565135 -0.10426244 -0.07835521  0.06448039  0.14670951]\n",
      " [-0.20147175  0.09190181 -0.24586309  0.10337565  0.04749255]\n",
      " [-0.20090441 -0.21248524  0.07256234  0.02600141  0.00576489]\n",
      " [-0.13626195 -0.17926001 -0.12466238 -0.22643685 -0.46666407]\n",
      " [ 0.00644162  0.03900838 -0.03109039 -0.34735346 -0.05286516]\n",
      " [ 0.14213613 -0.06959496 -0.05297527 -0.08671702 -0.09123591]\n",
      " [-0.06985927  0.2075852  -0.06273049  0.02758112  0.04032298]\n",
      " [-0.0469841  -0.10328721  0.1801237  -0.02509528 -0.01658229]\n",
      " [-0.0013714   0.03477187  0.04016502  0.17887971 -0.09425227]\n",
      " [ 0.09104182  0.05518619  0.06104055  0.02894771  0.25970192]] and its shape (15, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, Y)\n",
    "#Y_pred_lin = linreg.predict(X_test)\n",
    "#print(\"Linear regression score\", linreg.score(X, Y))\n",
    "print(\"X.shape,Y.shape\",X.shape,Y.shape)\n",
    "# print(\"B Matrix and its shape\",linreg.coef_,linreg.coef_.shape)\n",
    "print(\"B in paper corresponds to \",np.transpose(linreg.coef_),\"and its shape\", np.transpose(linreg.coef_).shape)\n",
    "#print(\"Root mean Square Error on the test data\", np.sqrt(mean_squared_error(Y_test, Y_pred_lin)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It optimizes the following objective function\n",
    "\n",
    "||y - Xw||^2_2 + alpha * ||w||^2_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B in paper corresponds to  [[ 0.54237126  0.22675622  0.19149682  0.0498004   0.04781158]\n",
      " [ 0.30868125  0.5924364   0.29438156 -0.18520527 -0.13595968]\n",
      " [ 0.333547    0.34503332  0.67175537  0.02657031 -0.05003863]\n",
      " [ 0.13702596  0.15744624  0.16049872  0.99203006  0.66736009]\n",
      " [-0.08194598 -0.0935088  -0.08854913  0.34123825  0.66115946]\n",
      " [ 0.16530647 -0.10436455 -0.07860188  0.06431851  0.14638148]\n",
      " [-0.20120817  0.09194308 -0.24556515  0.10262495  0.04700478]\n",
      " [-0.20032701 -0.21197217  0.07299362  0.02595839  0.00568255]\n",
      " [-0.13608452 -0.17882065 -0.12441867 -0.22538931 -0.46558462]\n",
      " [ 0.00608893  0.03843377 -0.03147345 -0.34705437 -0.05266613]\n",
      " [ 0.14212602 -0.06962063 -0.05300458 -0.08642327 -0.09069758]\n",
      " [-0.06991901  0.20748446 -0.06286564  0.02750352  0.0402203 ]\n",
      " [-0.04705545 -0.10325622  0.18017064 -0.02492964 -0.01667228]\n",
      " [-0.00124094  0.03478833  0.04031416  0.17884162 -0.09423322]\n",
      " [ 0.0909235   0.05517425  0.06089256  0.02844801  0.25921988]] and its shape (15, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "clf = Ridge(alpha=1)\n",
    "clf.fit(X, Y)\n",
    "#print(clf.coef_)\n",
    "print(\"B in paper corresponds to \",np.transpose(clf.coef_),\"and its shape\", np.transpose(clf.coef_).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It optimizes the following objective function\n",
    "\n",
    "(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B in paper corresponds to  [[0.74786324 0.16213154 0.05996371 0.         0.        ]\n",
      " [0.11283768 0.78666224 0.0552334  0.         0.        ]\n",
      " [0.11324651 0.02732862 0.85924372 0.0086367  0.        ]\n",
      " [0.         0.         0.         0.9244145  0.21086538]\n",
      " [0.         0.         0.         0.01417521 0.73553068]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]] and its shape (15, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "clf = Lasso(alpha=1)\n",
    "clf.fit(X, Y)\n",
    "#print(clf.coef_)\n",
    "print(\"B in paper corresponds to \",np.transpose(clf.coef_),\"and its shape\", np.transpose(clf.coef_).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It optimizes the following objective function\n",
    "\n",
    "1 / (2 * n_samples) * ||y - Xw||^2_2 + alpha * l1_ratio * ||w||_1  + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
    "\n",
    "\n",
    "If you are interested in controlling the L1 and L2 penalty separately, keep in mind that this is equivalent to:\n",
    "\n",
    "a * L1 + b * L2\n",
    "\n",
    "where:\n",
    "\n",
    "alpha = a + b and l1_ratio = a / (a + b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B in paper corresponds to  [[0.74786324 0.16213154 0.05996371 0.         0.        ]\n",
      " [0.11283768 0.78666224 0.0552334  0.         0.        ]\n",
      " [0.11324651 0.02732862 0.85924372 0.0086367  0.        ]\n",
      " [0.         0.         0.         0.9244145  0.21086538]\n",
      " [0.         0.         0.         0.01417521 0.73553068]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]] and its shape (15, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "clf = Lasso(random_state=0)\n",
    "clf.fit(X, Y)\n",
    "#print(clf.coef_)\n",
    "# If you run the command stand alone, you will get the following clf.fit(X, y) You can change those parameters if the performance is too bad.\n",
    "# ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
    "#       max_iter=1000, normalize=False, positive=False, precompute=False,\n",
    "#       random_state=0, selection='cyclic', tol=0.0001, warm_start=False)\n",
    "print(\"B in paper corresponds to \",np.transpose(clf.coef_),\"and its shape\", np.transpose(clf.coef_).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat  # this is the SciPy module that loads mat-files\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, time\n",
    "import pandas as pd\n",
    "from numpy.linalg import inv\n",
    "# mat = loadmat(r'C:\\Users\\dantongyu\\Downloads\\dtyu-granger-causality\\dtyu-granger-causality-645084c3e1f5\\SimulationExperiment\\Ridge\\analysis\\lambda_1_case_study\\filter_norm_expression.mat')  # load mat-file\n",
    "# mdata = mat['expression']\n",
    "# mdata=np.asmatrix(mdata)\n",
    "\n",
    "df=pd.read_csv(r\"C:\\Users\\dantongyu\\Downloads\\version\\data_vertical.csv\")\n",
    "#Its always better to perform normalization with respect to the particular sensor value\n",
    "df = (df - df.min())/(df.max()-df.min())\n",
    "list_all=[df['Sensor1'].values,df['Sensor2'].values,df['Sensor3'].values,df['Sensor4'].values,df['Sensor5'].values]\n",
    "mdata=np.asmatrix(list_all)\n",
    "\n",
    "period=3\n",
    "temp=mdata.shape\n",
    "n_gene=temp[0]\n",
    "Time_samples=temp[1]\n",
    "m=Time_samples-period\n",
    "#Y is starting its values for 2000 genes from the p+1 time instant till Time\n",
    "Y=mdata[:,period:Time_samples].T\n",
    "# Transpose is performed by .T as mdata is a matrix and the dimensions of the Y ----> m x n as shown in the paper\n",
    "# Here you take for all the variables at time t\n",
    "X=np.matlib.zeros((m, n_gene*period))\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(period):\n",
    "        #I have to take the large slices to run it faster\n",
    "#         print(X[i,n_gene*(j):n_gene*(j+1)].shape, (mdata[:,i+period-j-1].T).shape )\n",
    "        X[i,n_gene*(j):n_gene*(j+1)]=mdata[:,i+period-j-1].T\n",
    "#T-2 in python is nothing but T-1 matlab notation in reality   \n",
    "def ridge_regression(X,Y,lambd):\n",
    "    i=X.shape[1]\n",
    "    B= inv(X.T*X + lambd*np.identity(i))*X.T*Y\n",
    "    return B\n",
    "B=ridge_regression(X,Y,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression using time series sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape,Y.shape (1776, 15) (1776, 5)\n",
      "B in paper corresponds to  [[ 5.42467076e-01  2.23136321e-01  1.93875384e-01  7.18913476e-02\n",
      "   7.03530199e-02]\n",
      " [ 3.13254697e-01  5.92604314e-01  3.03354400e-01 -2.71178143e-01\n",
      "  -2.03338194e-01]\n",
      " [ 3.28866136e-01  3.35450502e-01  6.72507487e-01  3.76014855e-02\n",
      "  -7.24862880e-02]\n",
      " [ 9.57061678e-02  1.08336296e-01  1.13661110e-01  9.93330574e-01\n",
      "   6.82768950e-01]\n",
      " [-5.62517705e-02 -6.31846105e-02 -6.15749845e-02  3.33531738e-01\n",
      "   6.61117456e-01]\n",
      " [ 1.65651350e-01 -1.02740365e-01 -7.95334803e-02  9.26048147e-02\n",
      "   2.15280264e-01]\n",
      " [-2.04456518e-01  9.19018090e-02 -2.53257470e-01  1.50664506e-01\n",
      "   7.07226059e-02]\n",
      " [-1.97928045e-01 -2.06281291e-01  7.25623399e-02  3.67892293e-02\n",
      "   8.33403054e-03]\n",
      " [-9.48786879e-02 -1.22995917e-01 -8.81072487e-02 -2.26436852e-01\n",
      "  -4.76808939e-01]\n",
      " [ 4.38984445e-03  2.61954072e-02 -2.15061362e-02 -3.39962960e-01\n",
      "  -5.28651555e-02]\n",
      " [ 1.42136130e-01 -6.85789716e-02 -5.37718920e-02 -1.24540397e-01\n",
      "  -1.33878787e-01]\n",
      " [-7.08942271e-02  2.07585201e-01 -6.46171215e-02  4.01980210e-02\n",
      "   6.00461700e-02]\n",
      " [-4.62880394e-02 -1.00271528e-01  1.80123702e-01 -3.55071561e-02\n",
      "  -2.39722235e-02]\n",
      " [-9.54902496e-04  2.38580719e-02  2.83873094e-02  1.78879706e-01\n",
      "  -9.63012274e-02]\n",
      " [ 6.20433142e-02  3.70593390e-02  4.22235412e-02  2.83317972e-02\n",
      "   2.59701925e-01]] and its shape (15, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, Y)\n",
    "#Y_pred_lin = linreg.predict(X_test)\n",
    "#print(\"Linear regression score\", linreg.score(X, Y))\n",
    "print(\"X.shape,Y.shape\",X.shape,Y.shape)\n",
    "# print(\"B Matrix and its shape\",linreg.coef_,linreg.coef_.shape)\n",
    "print(\"B in paper corresponds to \",np.transpose(linreg.coef_),\"and its shape\", np.transpose(linreg.coef_).shape)\n",
    "#print(\"Root mean Square Error on the test data\", np.sqrt(mean_squared_error(Y_test, Y_pred_lin)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression\n",
    "It optimizes the following objective function\n",
    "\n",
    "||y - Xw||^2_2 + alpha * ||w||^2_2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B in paper corresponds to  [[ 0.17109378  0.14792974  0.15082829  0.03447371  0.04017786]\n",
      " [ 0.14674439  0.17537584  0.13344923  0.02552     0.02344519]\n",
      " [ 0.15370119  0.13710859  0.18573646  0.05055869  0.02177817]\n",
      " [ 0.04140453  0.04036461  0.05760393  0.30369106  0.25224693]\n",
      " [ 0.03981164  0.02961011  0.0228786   0.23453923  0.29274104]\n",
      " [ 0.10082744  0.08220045  0.08215498 -0.00837277  0.00412215]\n",
      " [ 0.07903666  0.11149549  0.06593612 -0.01464073 -0.01412283]\n",
      " [ 0.08465965  0.07193246  0.11666434  0.00526755 -0.01763125]\n",
      " [-0.01032008 -0.00868674  0.00479067  0.13872708  0.09196177]\n",
      " [-0.00384189 -0.00901118 -0.02152512  0.08134676  0.14307543]\n",
      " [ 0.0748267   0.06080077  0.06089673 -0.02082511 -0.00700521]\n",
      " [ 0.05580474  0.09214044  0.04722728 -0.02261083 -0.01824181]\n",
      " [ 0.06074698  0.05102449  0.09583089 -0.00586061 -0.02613242]\n",
      " [-0.01635225 -0.0106361   0.00191065  0.09326794  0.04777376]\n",
      " [-0.00537146 -0.00883876 -0.02034368  0.04202423  0.10361024]] and its shape (15, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "clf = Ridge(alpha=1)\n",
    "clf.fit(X, Y)\n",
    "#print(clf.coef_)\n",
    "print(\"B in paper corresponds to \",np.transpose(clf.coef_),\"and its shape\", np.transpose(clf.coef_).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso regression\n",
    "It optimizes the following objective function\n",
    "\n",
    "(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B in paper corresponds to  [[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]] and its shape (15, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "clf = Lasso(alpha=1)\n",
    "clf.fit(X, Y)\n",
    "#print(clf.coef_)\n",
    "print(\"B in paper corresponds to \",np.transpose(clf.coef_),\"and its shape\", np.transpose(clf.coef_).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic net\n",
    "It optimizes the following objective function\n",
    "\n",
    "1 / (2 * n_samples) * ||y - Xw||^2_2 + alpha * l1_ratio * ||w||1 + 0.5 * alpha * (1 - l1ratio) * ||w||^2_2\n",
    "\n",
    "If you are interested in controlling the L1 and L2 penalty separately, keep in mind that this is equivalent to:\n",
    "\n",
    "a * L1 + b * L2\n",
    "\n",
    "where:\n",
    "\n",
    "alpha = a + b and l1_ratio = a / (a + b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B in paper corresponds to  [[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]] and its shape (15, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "clf = Lasso(random_state=0)\n",
    "clf.fit(X, Y)\n",
    "#print(clf.coef_)\n",
    "# If you run the command stand alone, you will get the following clf.fit(X, y) You can change those parameters if the performance is too bad.\n",
    "# ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
    "#       max_iter=1000, normalize=False, positive=False, precompute=False,\n",
    "#       random_state=0, selection='cyclic', tol=0.0001, warm_start=False)\n",
    "print(\"B in paper corresponds to \",np.transpose(clf.coef_),\"and its shape\", np.transpose(clf.coef_).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
